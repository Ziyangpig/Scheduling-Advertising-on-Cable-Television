# -*- coding: utf-8 -*-
"""stage2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v5iY0UdOkMNKVaC24e4vXhJeQuSLOeUa
"""







import os
import pandas as pd
import pyomo.environ as pyo
from collections import defaultdict
import random

# --- 1. 安装依赖 (每次会话都需要) ---
print("STEP 1: 正在安装 COIN-OR CBC 求解器和 Pyomo...")
# !apt-get install -y -qq coinor-cbc
# !pip install -q pyomo
print("✅ 环境准备就绪！")

# ==============================================================================
# 单元格 2: 【新版本】创建 Stage 2 所需的详细数据文件
# 此版本会读取您上传的 stage1_weights.csv 来确保 deal_id 一致
# ==============================================================================
import pandas as pd
import random
import os

# --- 1. 创建 'data' 目录 ---
if not os.path.exists('data'):
    os.makedirs('data')

def create_stage2_input_files_from_real_stage1():
    """根据您上传的 Stage 1 文件，创建 Stage 2 当日运行所需的详细数据文件"""
    print("\n正在创建 Stage 2 的当日详细输入文件...")

    # 读取您上传的 stage1_weights.csv 来获取 deal 列表
    try:
        df_weights_uploaded = pd.read_csv('/content/output/stage1_weights.csv')
        deal_ids_from_stage1 = df_weights_uploaded['deal_id'].unique().tolist()
        print(f"成功读取到 Stage 1 的 Deal IDs: {deal_ids_from_stage1}")
    except FileNotFoundError:
        print("错误：无法找到 /content/output/stage1_weights.csv。请确保您已正确上传该文件。")
        return False

    # a. 创建 deals_stage2.csv (当日待播广告的详细信息)
    ads_data = []
    # 为每个从 Stage 1 读到的 deal 创建一些基础属性
    deals_base = {
        deal_id: {
            'target_demo': random.choice(['F18-34', 'M25-54', 'P25-54']),
            'advertiser': f'ADV{random.randint(1, 4)}',
            'brand': f'Brand{chr(65 + i)}', # BrandA, BrandB, etc.
            'category': f'Cat{random.choice(["X", "Y", "Z"])}'
        } for i, deal_id in enumerate(deal_ids_from_stage1)
    }

    ad_counter = 1
    for deal_id, props in deals_base.items():
        for _ in range(random.randint(5, 10)): # 每个deal当天有5-10条广告
            ads_data.append({
                'ad_id': f'Ad{ad_counter}', 'deal_id': deal_id,
                'length_sec': random.choice([15, 30, 60]),
                'target_demo': props['target_demo'], 'advertiser': props['advertiser'],
                'brand': props['brand'], 'category': props['category']
            })
            ad_counter += 1

    # 随机添加一些特殊约束的广告以测试模型的完整性
    if len(ads_data) > 12:
        ads_data[5]['is_A_pos'] = True
        ads_data[6]['is_Z_pos'] = True
        ads_data[7]['piggyback_with'] = f'Ad{9}'
        ads_data[8]['piggyback_with'] = f'Ad{8}'
        ads_data[10]['sandwich_with'] = f'Ad{12}'
        ads_data[11]['sandwich_with'] = f'Ad{11}'

    ads_df = pd.DataFrame(ads_data)
    # ads_df.to_csv('/content/data/deals_stage2.csv', index=False)
    # print(" -> /content/data/deals_stage2.csv 创建成功")

    # b. 创建 breaks_stage2.csv (当日的广告时段库存)
    breaks_data = []
    for i in range(1, 21): # 假设当天有20个时段
        breaks_data.append({
            'break_id': f'B{i}', 'length_sec': 1200,
            'start_minute_F_b': 480 + (i-1) * 20,
            'hour': 8 + ((i-1)*20 // 60)
        })
    breaks_df = pd.DataFrame(breaks_data)
    # breaks_df.to_csv('/content/data/breaks_stage2.csv', index=False)
    # print(" -> /content/data/breaks_stage2.csv 创建成功")

    # c. 创建 ratings_stage2.csv (当日的预测收视率)
    ratings_data = []
    demos = ['F18-34', 'M25-54', 'P25-54']
    for b in breaks_df['break_id']:
        for demo in demos:
            ratings_data.append({ 'break_id': b, 'demo_id': demo, 'rating': round(random.uniform(0.5, 3.0), 2) })
    ratings_df = pd.DataFrame(ratings_data)
    # ratings_df.to_csv('/content/data/ratings_stage2.csv', index=False)
    # print(" -> /content/data/ratings_stage2.csv 创建成功")
    return True

# --- 执行文件创建 ---
if create_stage2_input_files_from_real_stage1():
    print("\n✅ Stage 2 所需的当日详细数据文件已准备就绪。")

# ==============================================================================
# 单元格 3: 【新版本】加载并预处理所有数据
# 此版本会直接读取您上传的 stage1_weights.csv 和 stage1_xdb.csv
# ==============================================================================
import pandas as pd
from collections import defaultdict

print("正在加载和预处理数据...")

# --- 1. 加载所有CSV文件 ---
try:
    df_weights = pd.read_csv('/content/output/stage1_weights.csv')
    df_xdb = pd.read_csv('/content/output/stage1_xdb.csv')
    print("成功加载您上传的 Stage 1 输出文件。")
except FileNotFoundError as e:
    print(f"错误: 无法找到文件 {e.filename}。请确保您已正确上传文件到 /content/output/ 目录。")
    # 如果文件不存在，停止执行，防止后续代码出错
    raise e

df_ads = pd.read_csv('/content/data/deals_stage2.csv')
df_breaks = pd.read_csv('/content/data/breaks_stage2.csv')
df_ratings = pd.read_csv('/content/data/ratings_stage2.csv')
print("成功加载 Stage 2 的当日详细数据文件。")


# --- 2. 转换数据为Pyomo友好格式 ---
# a. 基础列表
ads_list = df_ads['ad_id'].tolist()
breaks_list = df_breaks['break_id'].tolist()
deals_list = df_weights['deal_id'].unique().tolist()
advertisers_list = df_ads['advertiser'].unique().tolist()
brands_list = df_ads['brand'].unique().tolist()
categories_list = df_ads['category'].unique().tolist()
hours_list = df_breaks['hour'].unique().tolist()

# b. 将DataFrames转换为字典以便快速查找
ads_data = df_ads.set_index('ad_id').to_dict('index')
breaks_data = df_breaks.set_index('break_id').to_dict('index')
ratings_pivot = df_ratings.pivot(index='break_id', columns='demo_id', values='rating').to_dict()
weights_data = df_weights.set_index('deal_id')['W_d'].to_dict()

# c. 补充广告数据中的权重
for ad_id, ad_props in ads_data.items():
    ads_data[ad_id]['W_d'] = weights_data.get(ad_props['deal_id'], 1.0)

# d. 预处理约束
allowed_placements = [(i, b) for i in ads_list for b in breaks_list]
separation_pairs = [('Ad1', 'Ad15', 30), ('Ad2', 'Ad20', 60)] if 'Ad20' in ads_list else []
a_pos_ads = {ad for ad, props in ads_data.items() if props.get('is_A_pos')}
z_pos_ads = {ad for ad, props in ads_data.items() if props.get('is_Z_pos')}
piggyback_pairs = {(ad, props['piggyback_with']) for ad, props in ads_data.items() if pd.notna(props.get('piggyback_with')) and ad < props['piggyback_with']}
sandwich_pairs = {(ad, props['sandwich_with']) for ad, props in ads_data.items() if pd.notna(props.get('sandwich_with')) and ad < props['sandwich_with']}

# e. 构建初始排期表 (Warm Start) - 【新逻辑】
# 完全基于您上传的 stage1_xdb.csv 文件
print("正在根据您上传的 stage1_xdb.csv 生成初始排期表 (Warm Start)...")
initial_schedule = {}
temp_xdb = df_xdb.rename(columns={'x_db': 'num_ads'}) # 兼容您的列名
temp_xdb_expanded = temp_xdb.loc[temp_xdb.index.repeat(temp_xdb.num_ads)].reset_index(drop=True)
ads_by_deal = df_ads.groupby('deal_id')['ad_id'].apply(list)

for deal_id, ads_in_deal in ads_by_deal.items():
    breaks_for_deal = temp_xdb_expanded[temp_xdb_expanded['deal_id'] == deal_id]['break_id'].tolist()
    if not breaks_for_deal: # 如果某个deal在xdb中没有记录
        print(f"警告：Deal {deal_id} 在 stage1_xdb.csv 中没有找到排期，将为其随机分配初始时段。")
        breaks_for_deal = random.choices(breaks_list, k=len(ads_in_deal))

    if len(breaks_for_deal) < len(ads_in_deal):
        breaks_for_deal *= (len(ads_in_deal) // len(breaks_for_deal) + 1)

    for ad_id, break_id in zip(ads_in_deal, breaks_for_deal):
        if break_id not in breaks_list: # 如果Stage1的时段不在今天的库存里
            initial_schedule[ad_id] = random.choice(breaks_list)
        else:
            initial_schedule[ad_id] = break_id

# 再次检查，确保所有广告都有初始位置
for ad_id in ads_list:
    if ad_id not in initial_schedule:
        initial_schedule[ad_id] = random.choice(breaks_list)

# f. 聚合数据用于模型
model_data = {
    'ads_list': ads_list, 'breaks_list': breaks_list, 'deals_list': deals_list,
    'advertisers_list': advertisers_list, 'brands_list': brands_list, 'categories_list': categories_list,
    'hours_list': hours_list, 'ads_data': ads_data, 'breaks_data': breaks_data,
    'ratings_pivot': ratings_pivot, 'initial_schedule': initial_schedule,
    'allowed_placements': allowed_placements, 'separation_pairs': separation_pairs,
    'a_pos_ads': a_pos_ads, 'z_pos_ads': z_pos_ads, 'piggyback_pairs': piggyback_pairs,
    'sandwich_pairs': sandwich_pairs
}

print("\n✅ 数据加载和预处理完成。")

# ==============================================================================
# 单元格 4: 完整版 Pyomo Stage 2 模型 (无省略)
# ==============================================================================
import pyomo.environ as pyo

def solve_stage2_full_model(data, Mmove_percent=0.5, PB=0.1, PA=0.1, PV=0.1):
    """
    使用 Pyomo 构建并求解 Stage 2 的完整 MIP 模型
    PB, PA, PV 是均匀分布约束的惩罚系数
    """
    print("\n--- 正在构建 Stage 2 完整版 MIP 模型 ---")

    # --- 1. 创建模型和集合 ---
    model = pyo.ConcreteModel(name="Stage2_Full_Ad_Scheduling")

    model.ADS = pyo.Set(initialize=data['ads_list'])
    model.BREAKS = pyo.Set(initialize=data['breaks_list'], ordered=True) # ordered=True很方便
    model.DEALS = pyo.Set(initialize=data['deals_list'])
    model.ADVERTISERS = pyo.Set(initialize=data['advertisers_list'])
    model.BRANDS = pyo.Set(initialize=data['brands_list'])
    model.HOURS = pyo.Set(initialize=data['hours_list'])

    # --- 2. 定义映射关系和子集 ---
    model.ads_in_deal = {d: [a for a in data['ads_list'] if data['ads_data'][a]['deal_id'] == d] for d in data['deals_list']}
    model.ads_in_brand = {br: [a for a in data['ads_list'] if data['ads_data'][a]['brand'] == br] for br in data['brands_list']}
    model.ads_in_advertiser = {adv: [a for a in data['ads_list'] if data['ads_data'][a]['advertiser'] == adv] for adv in data['advertisers_list']}
    model.breaks_in_hour = {h: [b for b in data['breaks_list'] if data['breaks_data'][b]['hour'] == h] for h in data['hours_list']}

    # --- 3. 定义决策变量 ---
    model.x = pyo.Var(model.ADS, model.BREAKS, domain=pyo.Binary)
    model.y = pyo.Var(model.ADS, domain=pyo.Binary)

    # 辅助变量 - 品牌/广告主均匀分布 (公式 13, 14)
    model.z_kb = pyo.Var(model.BRANDS, model.BREAKS, domain=pyo.Binary) # 品牌k是否在时段b出现
    model.alpha_kb = pyo.Var(model.BRANDS, model.BREAKS, domain=pyo.NonNegativeReals) # 惩罚值
    model.v_ab = pyo.Var(model.ADVERTISERS, model.BREAKS, domain=pyo.Binary) # 广告主a是否在时段b出现
    model.beta_ab = pyo.Var(model.ADVERTISERS, model.BREAKS, domain=pyo.NonNegativeReals) # 惩罚值

    # 辅助变量 - 时间均匀分布 (公式 15)
    model.theta_dh = pyo.Var(model.DEALS, model.HOURS, domain=pyo.NonNegativeReals)
    model.gamma_dh = pyo.Var(model.DEALS, model.HOURS, domain=pyo.NonNegativeReals)

    # 辅助变量 - 其他约束
    model.u = pyo.Var([(p[0], p[1]) for p in data['separation_pairs']], domain=pyo.Binary)

    # --- 4. 定义目标函数 (公式 11) ---
    def objective_rule(model):
        allocated_ratings = sum(
            data['ads_data'][i]['W_d'] * (data['ads_data'][i]['length_sec'] / 30.0) *
            data['ratings_pivot'][data['ads_data'][i]['target_demo']][b] * model.x[i, b]
            for i in model.ADS for b in model.BREAKS
        )
        binned_penalty = sum(
            data['ads_data'][i]['W_d'] * (data['ads_data'][i]['length_sec'] / 30.0) *
            data['ratings_pivot'][data['ads_data'][i]['target_demo']][data['initial_schedule'][i]] * model.y[i]
            for i in model.ADS
        )
        brand_penalty = PB * sum(model.alpha_kb[k, b] for k in model.BRANDS for b in model.BREAKS)
        advertiser_penalty = PA * sum(model.beta_ab[a, b] for a in model.ADVERTISERS for b in model.BREAKS)
        time_penalty = PV * sum(model.gamma_dh[d, h] for d in model.DEALS for h in model.HOURS)

        return allocated_ratings - binned_penalty - brand_penalty - advertiser_penalty - time_penalty

    model.objective = pyo.Objective(rule=objective_rule, sense=pyo.maximize)
    print(" -> 目标函数已定义")

    # --- 5. 定义约束 ---
    # (12a) 每个广告有唯一去处
    def ad_placement_rule(model, i):
        return sum(model.x[i, b] for b in model.BREAKS) + model.y[i] == 1
    model.ad_placement_con = pyo.Constraint(model.ADS, rule=ad_placement_rule)

    # (12b) 时段容量
    def break_capacity_rule(model, b):
        return sum(data['ads_data'][i]['length_sec'] * model.x[i, b] for i in model.ADS) <= data['breaks_data'][b]['length_sec']
    model.break_capacity_con = pyo.Constraint(model.BREAKS, rule=break_capacity_rule)

    # (12d) 最大移动数
    Mmove = int(len(data['ads_list']) * Mmove_percent)
    def max_moves_rule(model):
        ads_staying_put = sum(model.x[i, data['initial_schedule'][i]] for i in model.ADS)
        return len(data['ads_list']) - ads_staying_put <= Mmove
    model.max_moves_con = pyo.Constraint(rule=max_moves_rule)

    # (13) 品牌均匀分布
    def brand_presence_rule(model, k, b):
        return sum(model.x[i, b] for i in model.ads_in_brand[k]) <= len(model.ads_in_brand[k]) * model.z_kb[k,b]
    model.brand_presence_con = pyo.Constraint(model.BRANDS, model.BREAKS, rule=brand_presence_rule)
    def brand_penalty_rule(model, k, b):
        if b == model.BREAKS.last(): return pyo.Constraint.Skip
        # 使用 model.BREAKS.next(b) 获取下一个时段
        penalty_value = sum(data['ads_data'][i]['W_d'] * (data['ads_data'][i]['length_sec'] / 30.0) * data['ratings_pivot'][data['ads_data'][i]['target_demo']][b] * (model.x[i,b] - 1 + model.z_kb[k, model.BREAKS.next(b)]) for i in model.ads_in_brand[k])
        return model.alpha_kb[k,b] >= penalty_value
    model.brand_penalty_con = pyo.Constraint(model.BRANDS, model.BREAKS, rule=brand_penalty_rule)

    # (15) 时间均匀分布
    def time_dist_rule_pos(model, d, h):
        total_ads_for_deal = sum(model.x[i, b] for i in model.ads_in_deal[d] for b in model.BREAKS)
        avg_ads_per_hour = total_ads_for_deal / len(model.HOURS)
        ads_in_hour = sum(model.x[i, b] for i in model.ads_in_deal[d] for b in model.breaks_in_hour[h])
        return model.theta_dh[d,h] >= ads_in_hour - avg_ads_per_hour
    model.time_dist_con_pos = pyo.Constraint(model.DEALS, model.HOURS, rule=time_dist_rule_pos)

    def time_dist_rule_neg(model, d, h):
        total_ads_for_deal = sum(model.x[i, b] for i in model.ads_in_deal[d] for b in model.BREAKS)
        avg_ads_per_hour = total_ads_for_deal / len(model.HOURS)
        ads_in_hour = sum(model.x[i, b] for i in model.ads_in_deal[d] for b in model.breaks_in_hour[h])
        return model.theta_dh[d,h] >= avg_ads_per_hour - ads_in_hour
    model.time_dist_con_neg = pyo.Constraint(model.DEALS, model.HOURS, rule=time_dist_rule_neg)

    # # (16) A/Z-position
    # def a_pos_rule(model, b):
    #     return sum(model.x[i, b] for i in data['a_pos_ads']) <= 1
    # model.a_pos_con = pyo.Constraint(model.BREAKS, rule=a_pos_rule)
    # def z_pos_rule(model, b):
    #     return sum(model.x[i, b] for i in data['z_pos_ads']) <= 1
    # model.z_pos_con = pyo.Constraint(model.BREAKS, rule=z_pos_rule)

    # (18a) 关联约束 (piggyback & sandwich)
    def association_rule(model, i, j, b):
        return model.x[i, b] == model.x[j, b]
    model.association_con = pyo.Constraint(list(data['piggyback_pairs']) + list(data['sandwich_pairs']), model.BREAKS, rule=association_rule)

    # (18b) Sandwich 中间广告
    non_az_ads = [i for i in model.ADS if i not in data['a_pos_ads'] and i not in data['z_pos_ads']]
    def sandwich_middle_ad_rule(model, i, j, b):
        return sum(model.x[k, b] for k in non_az_ads if k not in [i, j]) >= model.x[i, b]
    model.sandwich_middle_ad_con = pyo.Constraint(list(data['sandwich_pairs']), model.BREAKS, rule=sandwich_middle_ad_rule)

    print(" -> 所有约束已定义")
    print("\n--- 正在求解模型 (这可能需要一些时间) ---")

    # --- 6. 求解 ---
    solver = pyo.SolverFactory('cbc')
    solver.options['seconds'] = 60 # 设置60秒超时
    results = solver.solve(model, tee=True)

    return model, results

# ==============================================================================
# 单元格 5: 执行求解并展示最终结果 (已更新，增加文件输出)
# ==============================================================================
import pandas as pd
import os
from collections import defaultdict

# --- 1. 执行模型求解 ---
# 确保在运行此单元格之前，前面的单元格都已成功运行
try:
    model_data
except NameError:
    print("错误：'model_data' 未定义。请确保您已按顺序运行了前面的所有代码单元格。")
else:
    model, results = solve_stage2_full_model(model_data, Mmove_percent=0.7)

    # --- 2. 格式化并打印结果 ---
    print("\n--- 最终结果 ---")
    if (results.solver.status == pyo.SolverStatus.ok) and (results.solver.termination_condition in [pyo.TerminationCondition.optimal, pyo.TerminationCondition.feasible]):
        if results.solver.termination_condition == pyo.TerminationCondition.optimal:
            print(f"✅ 状态: 找到最优解")
        else:
            print(f"⚠️ 状态: 找到可行解 (可能未达到最优)")

        print(f"最终目标函数值: {pyo.value(model.objective):.2f}")

        new_schedule = defaultdict(list)
        binned_ads = []

        # 从模型中提取排期结果
        for i in model.ADS:
            if pyo.value(model.y[i]) > 0.5:
                binned_ads.append(i)
            else:
                for b in model.BREAKS:
                    if pyo.value(model.x[i, b]) > 0.5:
                        new_schedule[b].append(i)
                        break

        print("\n--- 优化后的排期方案 ---")
        # 按照时段的开始时间排序，让输出更直观
        sorted_breaks = sorted(new_schedule.keys(), key=lambda k: model_data['breaks_data'][k]['start_minute_F_b'])
        for b in sorted_breaks:
            print(f"{b} (Hour {model_data['breaks_data'][b]['hour']}): {', '.join(sorted(new_schedule[b]))}")

        if binned_ads:
            print(f"\n被放入回收站的广告: {', '.join(binned_ads)}")

        print("\n--- 传送给 Stage 3 的数据 ---")
        output_for_stage3 = {b: sorted(ads) for b, ads in new_schedule.items()}
        print(output_for_stage3)

        # 确保 output 目录存在
        output_dir = 'output'
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"创建目录: {output_dir}")

        # 准备要写入文件的数据
        output_list = []
        # 添加已成功排期的广告
        for break_id, ads_in_break in new_schedule.items():
            for ad_id in ads_in_break:
                output_list.append({'ad_id': ad_id, 'break_id': break_id, 'status': 'Scheduled'})

        # 添加被放入回收站的广告
        for ad_id in binned_ads:
            output_list.append({'ad_id': ad_id, 'break_id': 'BINNED', 'status': 'Binned'})

        # 创建 DataFrame
        if output_list:
            df_schedule_output = pd.DataFrame(output_list)

            # (可选，但推荐) 关联原始广告信息，让输出文件内容更丰富
            df_ads_info = pd.read_csv('/content/data/deals_stage2.csv')
            df_final_output = pd.merge(df_schedule_output, df_ads_info, on='ad_id', how='left')

            # 调整列顺序并排序，方便查看
            cols_order = ['break_id', 'ad_id', 'deal_id', 'length_sec', 'target_demo', 'advertiser', 'brand', 'category', 'status']
            # 筛选出存在的列
            final_cols = [col for col in cols_order if col in df_final_output.columns]
            df_final_output = df_final_output[final_cols]
            df_final_output = df_final_output.sort_values(by=['break_id', 'ad_id']).reset_index(drop=True)

            # 保存到 CSV
            output_path = os.path.join(output_dir, 'stage2_schedule.csv')
            # df_final_output.to_csv(output_path, index=False, encoding='utf-8-sig')

    else:
        print(f"❌ 求解失败或未找到可行解。")
        print(f"求解器状态: {results.solver.status}")
        print(f"终止条件: {results.solver.termination_condition}")